{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bc8ffe5-a282-4e82-a6a8-89c4844a1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    \"\"\"Sinusoidal Positional Embedding for time conditioning.\"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = torch.exp(-torch.arange(half_dim, dtype=torch.float32) * (torch.log(torch.tensor(10000.0)) / (half_dim - 1)))\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        return torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.norm1 = nn.BatchNorm2d(out_channels)\n",
    "        self.norm2 = nn.BatchNorm2d(out_channels)\n",
    "        self.skip = nn.Conv2d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.norm1(self.conv1(x)))\n",
    "        h = self.norm2(self.conv2(h))\n",
    "        return F.relu(h + self.skip(x))\n",
    "\n",
    "class DownsampleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DownsampleBlock, self).__init__()\n",
    "        self.res_block = ResidualBlock(in_channels, out_channels)\n",
    "        self.downsample = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.res_block(x)\n",
    "        x = self.downsample(x)\n",
    "        return x\n",
    "\n",
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UpsampleBlock, self).__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.res_block = ResidualBlock(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.upsample(x)\n",
    "        x = self.res_block(x)\n",
    "        return x\n",
    "\n",
    "class DiffusionUNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, base_channels=64, time_dim=128):\n",
    "        super(DiffusionUNet, self).__init__()\n",
    "        self.initial_conv = nn.Conv2d(in_channels, base_channels, kernel_size=3, padding=1)\n",
    "        self.down1 = DownsampleBlock(base_channels, base_channels * 2)\n",
    "        self.down2 = DownsampleBlock(base_channels * 2, base_channels * 4)\n",
    "        self.down3 = DownsampleBlock(base_channels * 4, base_channels * 8)\n",
    "        self.middle = ResidualBlock(base_channels * 8, base_channels * 8)\n",
    "        self.up3 = UpsampleBlock(base_channels * 8, base_channels * 4)\n",
    "        self.up2 = UpsampleBlock(base_channels * 4, base_channels * 2)\n",
    "        self.up1 = UpsampleBlock(base_channels * 2, base_channels)\n",
    "        self.final_conv = nn.Conv2d(base_channels, 1, kernel_size=3, padding=1)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)  # Add global pooling\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial_conv(x)\n",
    "        x1 = self.down1(x)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        x_middle = self.middle(x3)\n",
    "        x = self.up3(x_middle + x3)\n",
    "        x = self.up2(x + x2)\n",
    "        x = self.up1(x + x1)\n",
    "        x = self.final_conv(x)\n",
    "        x = self.pool(x)  # Pool to [batch_size, 1, 1, 1]\n",
    "        return x.view(x.size(0))  # Flatten to [batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac7d019-806f-4e91-9f5c-6f233e155f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset placeholder class\n",
    "class CASIADataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "    \n",
    "        # Expand label to match the image dimensions if it's a binary classification map\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        label = label.expand((image.shape[1], image.shape[2]))  # Match height and width\n",
    "    \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6272862-36a3-45b7-acd2-2ea22d6c9f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "class CASIADataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Traverse through directories and collect image paths with labels\n",
    "        for label, folder in enumerate([\"Au\", \"Tp\"]):\n",
    "            folder_path = os.path.join(root_dir, folder)\n",
    "            for filename in os.listdir(folder_path):\n",
    "                if filename.endswith(('.tif', '.jpg', '.jpeg')):\n",
    "                    self.image_paths.append(os.path.join(folder_path, filename))\n",
    "                    self.labels.append(label)  # 0 for genuine, 1 for forged\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Dataset root directory (update this path)\n",
    "root_dir = \"C:/Users/ayush/Desktop/casia 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809cf66c-c04f-4993-b644-1c0470a841e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DiffusionUNet(in_channels=3, out_channels=1, base_channels=64)  # Single scalar output per sample\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "train_dataset = CASIADataset(root_dir=root_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)  # Outputs shape: [batch_size]\n",
    "        labels = labels.view(-1)  # Flatten labels to [batch_size]\n",
    "\n",
    "        loss = criterion(outputs, labels.float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predictions = torch.sigmoid(outputs) > 0.5\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epoch [{epoch+1}/10], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaed6e1-1a30-4706-9260-31d12dda74b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the transformation for the test dataset\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Define the test dataset root directory (update the path accordingly)\n",
    "test_root_dir = \"/kaggle/input/casia-2-test/casia 2 dataset test\"\n",
    "\n",
    "# Create the test dataset and DataLoader\n",
    "test_dataset = CASIADataset(root_dir=test_root_dir, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "with torch.no_grad():  # Disable gradient calculation for testing\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        predictions = torch.sigmoid(outputs.squeeze()) > 0.5  # Apply sigmoid and threshold at 0.5\n",
    "\n",
    "        # Collect predictions and true labels\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert to NumPy arrays for confusion matrix calculation\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(cm, classes = [\"Au\", \"Tp\"])\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(all_predictions, all_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
